<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  <link rel="shortcut icon" href="../img/favicon.ico">
  <title>2. Materials - Data Scraping</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="../css/highlight.css">
  
  <script>
    // Current page data
    var mkdocs_page_name = "2. Materials";
    var mkdocs_page_input_path = "materials.md";
    var mkdocs_page_url = "/materials/";
  </script>
  
  <script src="../js/jquery-2.1.1.min.js"></script>
  <script src="../js/modernizr-2.8.3.min.js"></script>
  <script type="text/javascript" src="../js/highlight.pack.js"></script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href=".." class="icon icon-home"> Data Scraping</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
	  
          
            <li class="toctree-l1">
		
    <a class="" href="..">1. Administration</a>
	    </li>
          
            <li class="toctree-l1 current">
		
    <a class="current" href="./">2. Materials</a>
    <ul class="subnav">
            
    <li class="toctree-l2"><a href="#week-1-intro-to-htmlcss">Week 1 - Intro to HTML/CSS</a></li>
    

    <li class="toctree-l2"><a href="#week-2-intro-to-python">Week 2 - Intro to Python</a></li>
    

    <li class="toctree-l2"><a href="#week-3-regular-dealing-with">Week 3 - Regular Expressions</a></li>
    

    <li class="toctree-l2"><a href="#week-4-beautifulsoup">Week 4 - BeautifulSoup</a></li>
    

    <li class="toctree-l2"><a href="#week-5-xml-files-and-lxml">Week 5 - XML files and LXML</a></li>
    

    <li class="toctree-l2"><a href="#week-6-scrapy">Week 6 - Scrapy</a></li>
    

    <li class="toctree-l2"><a href="#week-7-apis">Week 7 - APIs</a></li>
    

    <li class="toctree-l2"><a href="#week-8-beyond-scraping">Week 8 - Beyond scraping</a></li>
    

    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../homework/">3. Homework</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../exams/">4. Exams</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../resources/">5. Resources</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../additional/">6. Additional</a>
	    </li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="..">Data Scraping</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="..">Docs</a> &raquo;</li>
    
      
    
    <li>2. Materials</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h1 id="week-1-intro-to-htmlcss">Week 1 - Intro to HTML/CSS</h1>
<p>This component includes materials covered during the 1st week of the course (2 lectures of 2.5 hour duration).
During the first lecture the course objective, structure, content, tools and frame were covered.
During the 2nd lecture HTML/CSS were introduced and how to host them on GitHub as a webpage.</p>
<ol>
<li><a href="https://github.com/HrantDavtyan/Data_Scraping/tree/master/Week%201">All materials (slides + HTML/CSS files)</a></li>
</ol>
<h1 id="week-2-intro-to-python">Week 2 - Intro to Python</h1>
<p>This component includes materials covered during the 2nd week of the course (2 lectures of 2.5 hour duration). Python 2.7. programming language was introduced and Jupyter notebooks were used for executing the code. Topics covered include data types, control flow, functions, I/O. Packages covered include NumPy, Pandas, Matplotlib, Pandas DataReader.</p>
<ol>
<li><a href="http://nbviewer.jupyter.org/github/HrantDavtyan/Data_Scraping/blob/master/Week%202/Intro_1.ipynb">Intro to Python 1: the basics</a></li>
<li><a href="http://nbviewer.jupyter.org/github/HrantDavtyan/Data_Scraping/blob/master/Week%202/Intro_2.ipynb">Intro to Python 2: functions</a></li>
<li><a href="http://nbviewer.jupyter.org/github/HrantDavtyan/Data_Scraping/blob/master/Week%202/Intro_3.ipynb?flush_cache=true">Intro to Python 3: datareader</a></li>
</ol>
<h1 id="week-3-regular-dealing-with">Week 3 - Regular Expressions</h1>
<p>This component includes materials covered during the 3rd week of the course (2 lectures of 2.5 hour duration).Dealing  Regular expressions, native Python, as well as pandas imported read and write functions were introduced. Sublime text editor and Jupyter notebooks were used for executing the code. Topics covered include reading documents (csv, json, html, txt), writing files (csv, json), Regular expressions, parsing json as well as creating simple bot operating on Markvo chains. Packages covered include Pandas, JSON, RegEx, MarkovBot.</p>
<ol>
<li><a href="http://nbviewer.jupyter.org/github/HrantDavtyan/Data_Scraping/blob/master/Week%203/W3_Readin_files_1.ipynb">Reading and writing files (pure)</a></li>
<li><a href="http://nbviewer.jupyter.org/github/HrantDavtyan/Data_Scraping/blob/master/Week%203/W3_Readin_files_2.ipynb">Reading and Writing files (Pandas)</a></li>
<li><a href="http://nbviewer.jupyter.org/github/HrantDavtyan/Data_Scraping/blob/master/Week%203/W3_RegEx_1.ipynb">RegEx 1: financier, e-mail</a></li>
<li><a href="http://nbviewer.jupyter.org/github/HrantDavtyan/Data_Scraping/blob/master/Week%203/W3_RegEx_2.ipynb">RegEx 2: requests, HTML</a></li>
<li><a href="http://nbviewer.jupyter.org/github/HrantDavtyan/Data_Scraping/blob/master/Week%203/JSON_part_1.ipynb">Dealing with JSON files 1</a></li>
<li><a href="http://nbviewer.jupyter.org/github/HrantDavtyan/Data_Scraping/blob/master/Week%204/JSON.ipynb">Dealing with JSON files 2</a></li>
</ol>
<h1 id="week-4-beautifulsoup">Week 4 - BeautifulSoup</h1>
<p>This component includes materials covered during the 4th week of the course (2 lectures of 2.5 hour duration). Scraping HTML webpages with BeautifulSoup was introduced. Sublime text editor and Jupyter notebooks were used for executing the code. Topics covered include reading and writing CSV files using the CSV module, reading and writing JSON files using the JSON modeule, web scraping with BeautifulSoup using the HTML tags/CSS selectors. Packages covered include JSON, CSV, urllib, BeautifulSoup.</p>
<ol>
<li><a href="http://nbviewer.jupyter.org/github/HrantDavtyan/Data_Scraping/blob/master/Week%204/B_soup_1_%28my_page%29.ipynb?=True">BeautifulSoup 1: My webpage</a></li>
<li><a href="http://nbviewer.jupyter.org/github/HrantDavtyan/Data_Scraping/blob/master/Week%204/B_soup_2_%28Bloomberg%29.ipynb?=True">BeautifulSoup 2: Bloomberg</a></li>
<li><a href="http://nbviewer.jupyter.org/github/HrantDavtyan/Data_Scraping/blob/master/Week%204/B_soup_3_%28careercenter%29.ipynb?=True">BeautifulSoup 3: www.careercenter.am</a></li>
<li><a href="http://nbviewer.jupyter.org/github/HrantDavtyan/Data_Scraping/blob/master/Week%204/B_soup_4_%28navigation%29.ipynb?=True">BeautifulSoup 4: Navigation</a></li>
<li><a href="http://nbviewer.jupyter.org/github/HrantDavtyan/Data_Scraping/blob/master/Week%204/Craftcans.com_pandas.ipynb?=True">Craftcans.com - Pandas</a></li>
<li><a href="http://nbviewer.jupyter.org/github/HrantDavtyan/Data_Scraping/blob/master/Week%204/Craftcans.com_BeautifulSoup.ipynb?=True">Craftcans.com - BeautifulSoup</a></li>
<li><a href="http://nbviewer.jupyter.org/github/HrantDavtyan/Data_Scraping/blob/master/Week%204/Craftcans.com_cleaning.ipynb?=True">Craftcans.com - cleaning</a></li>
</ol>
<h1 id="week-5-xml-files-and-lxml">Week 5 - XML files and LXML</h1>
<p>This component includes materials covered during the 5th week of the course (2 lectures of 2.5 hour duration). Overview of the first 4 week material was provided followed by a midterm exam (exam paper available in this folder). During the 2nd lecture alternative libraries for scraping were covered (urllib2 as an alternative to requests, and lxml as an alternative to BeautifulSoup). Sublime text editor and Jupyter notebooks were used for executing the code. Topics covered include working with XML documents, scraping the web using XPath, differences between lxml and BeautifulSoup. Packages covered include LXML and urllib2.</p>
<ol>
<li><a href="http://nbviewer.jupyter.org/github/HrantDavtyan/Data_Scraping/blob/master/Week%205/Alternative_approach_%28urllib_and_LXML%29.ipynb?=True">Alternative libraries for scraping</a></li>
<li><a href="http://nbviewer.jupyter.org/github/HrantDavtyan/Data_Scraping/blob/master/Week%205/Working_with_XML_docs.ipynb?=True">Working with XML documents</a></li>
</ol>
<h1 id="week-6-scrapy">Week 6 - Scrapy</h1>
<p>This component includes materials covered during the 6th week of the course (2 lectures of 2.5 hour duration). Scrapy scraping and crawling framework was introduced following the official documentation. Sublime text editor and command prompt (directly) were used for executing the code (also Jupyter notebooks were used for sharing the code). Topics covered include scraping quotes, putting timer, naming the agent, crawling over several pages. Packages covered include Scrapy, pacf.</p>
<ol>
<li><a href="http://nbviewer.jupyter.org/github/HrantDavtyan/Data_Scraping/blob/master/Week%206/Scrapy_1.ipynb">Scrapy 1: using inside shell</a></li>
<li><a href="http://nbviewer.jupyter.org/github/HrantDavtyan/Data_Scraping/blob/master/Week%206/Scrapy_2.ipynb">Scrapy 2: developing a spider</a></li>
<li><a href="http://nbviewer.jupyter.org/github/HrantDavtyan/Data_Scraping/blob/master/Week%206/Scrapy_3.ipynb">Scrapy 3: developing a crawler</a></li>
<li><a href="http://nbviewer.jupyter.org/github/HrantDavtyan/Data_Scraping/blob/master/Week%206/YouTube_API.ipynb">YouTube API: unauthorized access</a></li>
</ol>
<h1 id="week-7-apis">Week 7 - APIs</h1>
<h1 id="week-8-beyond-scraping">Week 8 - Beyond scraping</h1>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../homework/" class="btn btn-neutral float-right" title="3. Homework">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href=".." class="btn btn-neutral" title="1. Administration"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
	  
        </div>
      </div>

    </section>
    
  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
        <span><a href=".." style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../homework/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script src="../js/theme.js"></script>
      <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>

</body>
</html>
