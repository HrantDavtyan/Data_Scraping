{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BeautifulSoup 2: Bloomberg\n",
    "\n",
    "This notebooks shows how to get an index name and value (also for multiple indicies) from the Bloomberg page. Reminder: first of all you need to check the robots.txt file to see whether we are allowed to scrape or not (being nice) and then go on, if everything is okay.\n",
    "\n",
    "### The current value of S&P index\n",
    "\n",
    "Let's find the current value of S&P index. Again, we should import the 2 libraries for getting the HTML page (**requests**) and for dealing with it (**BeautifulSoup**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from BeautifulSoup import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = \"http://www.bloomberg.com/quote/SPX:IND\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response = requests.get(url)\n",
    "page = response.text\n",
    "soup = BeautifulSoup(page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you check use the Inspect element feature from Google Chrome, you will see that the name of the index is inside an ```<h1>``` tag which has a class = name attribute. Let's first find all the ```<h1>``` guys from the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h1 class=\"bb-nav-logo\" is=\"bb-nav-logo\"> <div class=\"bb-nav-logo__rubix\" data-tracker-label=\"bomb.open.rubix_button\" data-tracker-action=\"click\"></div> <div class=\"bb-nav-logo__menu\" data-tracker-label=\"bomb.open.menu_button\" data-tracker-action=\"click\"> <div class=\"bb-nav-logo__menu-link\">MENU</div> </div> <a href=\"http://www.bloomberg.com\" class=\"bb-nav-logo__link\" data-tracker-label=\"logo\" data-tracker-action=\"click\"></a> <div class=\"bb-nav-logo__arrow\"></div> </h1>,\n",
       " <h1 class=\"bb-nav-content-logo__headline\" data-tracker-label=\"content\"> <a href=\"http://www.bloomberg.com\" class=\"bb-nav-content-logo__site\" data-tracker-label=\"logo\" data-tracker-action=\"click\"></a> </h1>,\n",
       " <h1 class=\"name\"> S&amp;P 500 Index </h1>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.findAll('h1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, this is not what we want (index name). Thus, we shoudl explicitly mention the attributes we are looking for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h1 class=\"name\"> S&amp;P 500 Index </h1>]\n"
     ]
    }
   ],
   "source": [
    "index_name = soup.findAll('h1', attrs={'class': 'name'})\n",
    "print(index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, this works, we ere able to find the correct tag. Let's get the text out of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S&amp;P 500 Index\n"
     ]
    }
   ],
   "source": [
    "print(index_name[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason we used index_name[0] notation is that index_name is a list (although consisting of only one element, but still a list). The **text** methods works only on strings/tags, so we had to explicitly choose the tag from the list and then apply **text** method on it.\n",
    "\n",
    "Similarly, we can use the Inspect element feature to understand where the index value is lying in and get it. Then we can get the text part out of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,429.39\n"
     ]
    }
   ],
   "source": [
    "index_value = soup.findAll('div', attrs={'class':'price'})\n",
    "print(index_value[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple indices (print)\n",
    "\n",
    "If one is interested in getting data on multiple indicies then you just need to specify all the urls you want to get data from inside a list, and then create a for loop that will iterate over that list, send a request, get the response and convert to text(as we did above and before), pass it as an argument to **BeautifulSoup()** function and get the index name and value as done above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "urls = [\"https://www.bloomberg.com/quote/DM1:IND\",\n",
    "        \"https://www.bloomberg.com/quote/UKX:IND\",\n",
    "        \"https://www.bloomberg.com/quote/EURUSD:CUR\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dow Jones mini Futures: 21,207.00\n",
      "\n",
      "FTSE 100 Index: 7,511.87\n",
      "\n",
      "EURUSD Spot Exchange Rate: 1.1187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for url in urls:\n",
    "    response = requests.get(url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page)\n",
    "    index_name = soup.find(\"h1\",attrs={'class':'name'})\n",
    "    index_value = soup.find(\"div\",attrs={'class':'price'})\n",
    "    print(index_name.text+\": \"+index_value.text+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple indices (save to dict)\n",
    "\n",
    "If one is interested in saving the results, let's say into a dictionary, then you should first create an empty dictionary, then update its content by usning the **update()** function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_data = {}\n",
    "\n",
    "for url in urls:\n",
    "    response = requests.get(url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page)\n",
    "    index_name = soup.find(\"h1\",attrs={'class':'name'})\n",
    "    index_value = soup.find(\"div\",attrs={'class':'price'})\n",
    "    my_data.update({index_name.text:index_value.text})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pretty print the content of the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'Dow Jones mini Futures': u'21,207.00',\n",
      " u'EURUSD Spot Exchange Rate': u'1.1186',\n",
      " u'FTSE 100 Index': u'7,511.87'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(my_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Being nice\n",
    "\n",
    "Once you create a for loop to send a request, get the data and so on, you should be attentive not to overwhelm the website server. For that purpose you may want to ask your for loop to sleep a bit between each iteration (let's say 10 seconds). We may use the **time** library and **sleep()** function from that library to make for loop sleep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is the same code as above with 2 additional lines\n",
    "import time # importing the library\n",
    "my_data = {}\n",
    "for url in urls:\n",
    "    response = requests.get(url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page)\n",
    "    index_name = soup.find(\"h1\",attrs={'class':'name'})\n",
    "    index_value = soup.find(\"div\",attrs={'class':'price'})\n",
    "    my_data.update({index_name.text:index_value.text})\n",
    "    time.sleep(10) # asking for loop to sleep 10 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, different websites mention in their documentation how long you need to *sleep* before each request. THe average duration is 30 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to CSV (with datatime)\n",
    "\n",
    "We may want to save the resutls into a CSV file. For that reason we must use the CSV library. If you also want to save the date and the time, then the **datetime** library will be useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "with open(\"index_data.csv\",\"w\") as file: # create a new file for writing purposes\n",
    "    writer = csv.writer(file)\n",
    "    for i in my_data:\n",
    "        writer.writerow([i,my_data[i],datetime.now()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct a dataframe\n",
    "\n",
    "You may want to construct a pandas dataframe from the dictionary we had. the **DataFrame.from_dict()** functino from the **pandas** library might be useful. THe function takes two arguments: first the dictionary to get the data from, and second argument, which shows whether the dictionary keys should become row names (index) or column names in our dataframe. Let's make them row names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   0\n",
      "FTSE 100 Index              7,511.87\n",
      "EURUSD Spot Exchange Rate     1.1187\n",
      "Dow Jones mini Futures     21,207.00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame.from_dict(my_data,\"index\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transpose the dataframe\n",
    "\n",
    "If you wanted to have dictionary keys as column names, you may transpose the dataframe as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FTSE 100 Index</th>\n",
       "      <th>EURUSD Spot Exchange Rate</th>\n",
       "      <th>Dow Jones mini Futures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7,511.87</td>\n",
       "      <td>1.1187</td>\n",
       "      <td>21,207.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  FTSE 100 Index EURUSD Spot Exchange Rate Dow Jones mini Futures\n",
       "0       7,511.87                    1.1187              21,207.00"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And of course, if we are dealing with pandas, we can easily save the dataframe to csv as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.transpose().to_csv(\"index_dataframe.csv\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
