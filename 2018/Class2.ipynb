{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Scraping HTML pages\n",
        "\n",
        "This notebook provides introduction to web (data) scraping using **requests**, **BeautifulSoup** and **Pandas** libraries.\n",
        "\n",
        "### Descriptions\n",
        "\n",
        "- **requests** - provides a **get()** function that gets the HTML source of the given page. **status_code** method tells us whether the request was succesfully responded (i.e. 200) or not (i.e. 404 error). In case of success once may use the **content** method to get only the HTML content (without status code etc.) for further scraping.\n",
        "- **pandas** - the most popular Python package for data analysis and manipulation. Provides many nice functions for reading different files, including a **read_html()** function for reading HTML tables. **Attention!**: it will read only tables and save the output as a list of dataframes. Nothing else than the text content of <table> tags will be sabed.\n",
        "- **BeautifulSoup** - provides a lot of nice functions for scraping data in Python, that are only applicable for BeautilfulSoup elements. Thus, first of all **BeautilfulSoup()** function should be used to convert the *page* into BeautifulSoup type of object, and then apply the below mentioned functions.\n",
        "    \n",
        "        - find_all() - when used on BeautifulSoup element, will find all the tags required. Class or ID can be specified as well to make the search more precise. This function returns a list of BeautifulSoup elements.\n",
        "        - find() - works as find_all(), however finds only the very first element matching the criteria. Is useful especially when one is sure only one element satisfies the required criteria. Returns BeautifulSoup element directly.\n",
        "        - get_text() - provide only text content from BeautifulSoup element (i.e. without tags).\n",
        "        - get() - gets the value of required argument, i.e. get(\"href\") will provide the hyperlink mentioned in some <a> tag.\n",
        "\n",
        "This notebook provides the following cases:\n",
        "\n",
        "1. Quotes to Scrape,\n",
        "2. Books to Scrape,\n",
        "3. Unicorn companies, CBInsights\n",
        "4. Careercenter"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np #for numeric operations\n",
        "import pandas as pd #for dealing with dataframes\n",
        "import matplotlib.pyplot as plt #for visualization\n",
        "\n",
        "import requests #get html\n",
        "from bs4 import BeautifulSoup #for scraping\n",
        "from pprint import pprint #for pretty printing"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Case 1: Quotes to Scrape"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#robots.txt checked\n",
        "url = \"http://quotes.toscrape.com/\""
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#get html\n",
        "response = requests.get(url)\n",
        "response.status_code #200 then good, 404 then bad"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "page=response.content #html to scrape\n",
        "page = BeautifulSoup(page,\"html.parser\") #change type"
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#find all hashtags, extract text from the first\n",
        "hashtags_html = page.find_all(\"a\",class_ = \"tag\") #tag finder\n",
        "hashtags_html[0].get_text() #get text from the whole tag"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 39,
          "data": {
            "text/plain": [
              "'change'"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 39,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#extract text from all hashtags and save it\n",
        "#Appraoch 1: for loop\n",
        "hashtags = []\n",
        "for i in hashtags_html:\n",
        "    hashtags.append(i.get_text())\n",
        "print(hashtags)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['change', 'deep-thoughts', 'thinking', 'world', 'abilities', 'choices', 'inspirational', 'life', 'live', 'miracle', 'miracles', 'aliteracy', 'books', 'classic', 'humor', 'be-yourself', 'inspirational', 'adulthood', 'success', 'value', 'life', 'love', 'edison', 'failure', 'inspirational', 'paraphrased', 'misattributed-eleanor-roosevelt', 'humor', 'obvious', 'simile', 'love', 'inspirational', 'life', 'humor', 'books', 'reading', 'friendship', 'friends', 'truth', 'simile']\n"
          ]
        }
      ],
      "execution_count": 43,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Appraoch 2: get texts using list comprehension\n",
        "hashtags = [i.get_text() for i in hashtags_html] \n",
        "print(hashtags)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['change', 'deep-thoughts', 'thinking', 'world', 'abilities', 'choices', 'inspirational', 'life', 'live', 'miracle', 'miracles', 'aliteracy', 'books', 'classic', 'humor', 'be-yourself', 'inspirational', 'adulthood', 'success', 'value', 'life', 'love', 'edison', 'failure', 'inspirational', 'paraphrased', 'misattributed-eleanor-roosevelt', 'humor', 'obvious', 'simile', 'love', 'inspirational', 'life', 'humor', 'books', 'reading', 'friendship', 'friends', 'truth', 'simile']\n"
          ]
        }
      ],
      "execution_count": 45,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#from now on, use list comprehensions for simplicity\n",
        "#get links\n",
        "links = [i.get(\"href\") for i in hashtags_html]\n",
        "pprint(links)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/tag/change/page/1/',\n",
            " '/tag/deep-thoughts/page/1/',\n",
            " '/tag/thinking/page/1/',\n",
            " '/tag/world/page/1/',\n",
            " '/tag/abilities/page/1/',\n",
            " '/tag/choices/page/1/',\n",
            " '/tag/inspirational/page/1/',\n",
            " '/tag/life/page/1/',\n",
            " '/tag/live/page/1/',\n",
            " '/tag/miracle/page/1/',\n",
            " '/tag/miracles/page/1/',\n",
            " '/tag/aliteracy/page/1/',\n",
            " '/tag/books/page/1/',\n",
            " '/tag/classic/page/1/',\n",
            " '/tag/humor/page/1/',\n",
            " '/tag/be-yourself/page/1/',\n",
            " '/tag/inspirational/page/1/',\n",
            " '/tag/adulthood/page/1/',\n",
            " '/tag/success/page/1/',\n",
            " '/tag/value/page/1/',\n",
            " '/tag/life/page/1/',\n",
            " '/tag/love/page/1/',\n",
            " '/tag/edison/page/1/',\n",
            " '/tag/failure/page/1/',\n",
            " '/tag/inspirational/page/1/',\n",
            " '/tag/paraphrased/page/1/',\n",
            " '/tag/misattributed-eleanor-roosevelt/page/1/',\n",
            " '/tag/humor/page/1/',\n",
            " '/tag/obvious/page/1/',\n",
            " '/tag/simile/page/1/',\n",
            " '/tag/love/',\n",
            " '/tag/inspirational/',\n",
            " '/tag/life/',\n",
            " '/tag/humor/',\n",
            " '/tag/books/',\n",
            " '/tag/reading/',\n",
            " '/tag/friendship/',\n",
            " '/tag/friends/',\n",
            " '/tag/truth/',\n",
            " '/tag/simile/']\n"
          ]
        }
      ],
      "execution_count": 52,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#get hashtags from links, treating links as string\n",
        "hashtags_from_links = [i.split(\"/\")[2] for i in links]"
      ],
      "outputs": [],
      "execution_count": 63,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "authors_html = page.find_all(\"small\",class_ = \"author\")\n",
        "authors = [i.get_text() for i in authors_html]\n",
        "print(authors)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Albert Einstein', 'J.K. Rowling', 'Albert Einstein', 'Jane Austen', 'Marilyn Monroe', 'Albert Einstein', 'Andr√© Gide', 'Thomas A. Edison', 'Eleanor Roosevelt', 'Steve Martin']\n"
          ]
        }
      ],
      "execution_count": 66,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Case 2: Books to Scrape"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#get the HTML page and make it BeautifulSoup type\n",
        "url = \"http://books.toscrape.com/\"\n",
        "response  = requests.get(url)\n",
        "page = response.content\n",
        "page = BeautifulSoup(page,\"html.parser\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#find tags with prices, get text only, convert to numeric format\n",
        "prices_html = page.find_all(\"p\",class_=\"price_color\")\n",
        "prices = [i.get_text() for i in prices_html]\n",
        "prices_numeric = [float(i.replace(\"¬£\",\"\")) for i in prices]\n",
        "print(prices_numeric)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#convert prices back to text and save in a txt file (each on new line)\n",
        "with open(\"prices.txt\",\"w\") as f:\n",
        "    for i in prices_numeric:\n",
        "        f.write(str(i)+\"\\n\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will try to get book titles. The difficulty of hte task is that its link does not have an identifier. We will try 3 solutions, first will not work, the other 2 will."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#trial 1 - parent search (did not work)\n",
        "article_tag = page.find_all(\"article\",class_=\"product_pod\")\n",
        "titles_wrong = [i.get_text() for i in article_tag]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#trial 2 - for loop\n",
        "#find all h3 tags then first (only) a tags inside\n",
        "h3s = page.find_all(\"h3\")\n",
        "titles = [i.find(\"a\").get_text() for i in h3s]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#trial 3 - content of <a>\n",
        "#find all a tags, then choose only those that\n",
        "#have the keyword title inside and get their text\n",
        "a_tags = page.find_all(\"a\")\n",
        "titles = []\n",
        "for i in a_tags:\n",
        "    if str(i).find(\"title=\")>-1:\n",
        "        text = i.get_text()\n",
        "        titles.append(text)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Case 3: Unicorn companies, CBInsights"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://www.cbinsights.com/research-unicorn-companies\"\n",
        "#as the data is provided inside an HTML table, we can use pandas to read it\n",
        "data = pd.read_html(url)\n",
        "#result is a list of one lement, which turns out to be a daraframe\n",
        "type(data[0])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "startups = data[0]\n",
        "startups.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Case 4: Careercenter"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "url_career = \"https://careercenter.am/ccidxann.php\"\n",
        "tables_career = pd.read_html(url_career)\n",
        "len(tables_career)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#it turned out there were 5 tables on this website, we ar einterested in the first one\n",
        "tables_career[0].head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tables_career[0].to_csv(\"jobs.csv\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "nteract": {
      "version": "0.8.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
